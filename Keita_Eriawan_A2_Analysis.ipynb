{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <strong> Classification Model Case Study <br>\n",
    "02/05/2020 | DAT-5303 Machine Learning </h4>\n",
    "<br> Author: Keita Eriawan <br>\n",
    "Hult International Business School<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprentice Chef has given the task to create a machine learning model that predicts which customer would subscribes to their service. The service that they are launching is Halfway There, a cross-selling promotion where subscribers receive a half bottle of wine from a local California vineyard every Wednesday. \n",
    "\n",
    "The target variable is CROSS_SELL_SUCCESS\n",
    "\n",
    "In this analysis, I will be creating a classification model from the Apprentice Chef Dataset. I will be following these stages for my analysis:\n",
    "\n",
    "1. Importing the data\n",
    "2. Exploring the data\n",
    "3. Feature Engineering \n",
    "4. Building the model\n",
    "5. Presenting the results\n",
    "\n",
    "We skipped the data cleaning process because the data that was given was already queried, sampled and verified. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 1. Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the required packages #\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn packages #\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.metrics         import confusion_matrix       \n",
    "from sklearn.metrics         import roc_auc_score          \n",
    "from sklearn.neighbors       import KNeighborsClassifier   \n",
    "from sklearn.neighbors       import KNeighborsRegressor    \n",
    "from sklearn.preprocessing   import StandardScaler \n",
    "from sklearn.model_selection import GridSearchCV     \n",
    "from sklearn.metrics         import make_scorer \n",
    "from sklearn.ensemble        import RandomForestClassifier     \n",
    "from sklearn.ensemble        import GradientBoostingClassifier \n",
    "\n",
    "# Decision-Tree packages #\n",
    "from sklearn.tree import DecisionTreeClassifier      \n",
    "from sklearn.tree import export_graphviz             \n",
    "from sklearn.externals.six import StringIO           \n",
    "from IPython.display import Image                   \n",
    "import pydotplus  \n",
    "\n",
    "# Setting pandas print option #\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Specifying the file name #\n",
    "file = 'Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "# Reading the file #\n",
    "apprentice_chef = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 2. Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have imported all of the necessary packages and dataset, I would like to know what the dataset looks like. I will run the .info(), .describe() and .head() to showcase the data in a summarized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 rows of the dataset #\n",
    "# apprentice_chef.head()\n",
    "\n",
    "# Info about the dataset #\n",
    "# apprentice_chef.info()\n",
    "\n",
    "# Summary on the dataset #\n",
    "# apprentice_chef.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be easier to analyze data visually so in this stage, I will be creating two graphs; barplot to check the frequencies of each variables and scatterplot to see the relationship between the independent variable and dependent variable (CROSS_SELL_SUCCESS). For the barplot, I will be commenting it out to make the notebook run efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Bar graph for outliers detection ###\n",
    "\n",
    "# # Figure and axis size #\n",
    "# fig, ax = plt.subplots(figsize = (10, 10)) # fitting the axis \n",
    "\n",
    "\n",
    "# revenue #\n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.distplot(apprentice_chef['REVENUE'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'g')\n",
    "# plt.xlabel('REVENUE')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "\n",
    "# total_meals_ordered #\n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.distplot(apprentice_chef['TOTAL_MEALS_ORDERED'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'b')\n",
    "# plt.xlabel('TOTAL_MEALS_ORDERED')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# unique_meals_purch #\n",
    "# plt.subplot(2, 2, 3)\n",
    "# sns.distplot(apprentice_chef['UNIQUE_MEALS_PURCH'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'g')\n",
    "# plt.xlabel('UNIQUE_MEALS_PURCH')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "\n",
    "# contacts_w_customer_service #\n",
    "# plt.subplot(2, 2, 4)\n",
    "# sns.distplot(apprentice_chef['CONTACTS_W_CUSTOMER_SERVICE'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'b')\n",
    "# plt.xlabel('CONTACTS_W_CUSTOMER_SERVICE')\n",
    "# plt.ylabel('frequency')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "# Figure and axis size #\n",
    "# fig, ax = plt.subplots(figsize = (10, 10)) # fitting the axis \n",
    "\n",
    "# product_categories_viewed #\n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.distplot(apprentice_chef['PRODUCT_CATEGORIES_VIEWED'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'r')\n",
    "# plt.xlabel('PRODUCT_CATEGORIES_VIEWED')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# avg_time_per_site_visit # \n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.distplot(apprentice_chef['AVG_TIME_PER_SITE_VISIT'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'y')\n",
    "# plt.xlabel('AVG_TIME_PER_SITE_VISIT')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# mobile_number # \n",
    "# plt.subplot(2, 2, 3)\n",
    "# sns.distplot(apprentice_chef['MOBILE_NUMBER'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'r')\n",
    "# plt.xlabel('MOBILE_NUMBER')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# cancellations_before_noon # \n",
    "# plt.subplot(2, 2, 4)\n",
    "# sns.distplot(apprentice_chef['CANCELLATIONS_BEFORE_NOON'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'y')\n",
    "# plt.xlabel('CANCELLATIONS_BEFORE_NOON')\n",
    "# plt.ylabel('frequency')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "# Figure and axis size #\n",
    "# fig, ax = plt.subplots(figsize = (10, 10)) # fitting the axis \n",
    "\n",
    "# # cancellations_after_noon #\n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.distplot(apprentice_chef['CANCELLATIONS_AFTER_NOON'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'g')\n",
    "# plt.xlabel('CANCELLATIONS_AFTER_NOON')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# tastes_and_preferences #\n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.distplot(apprentice_chef['TASTES_AND_PREFERENCES'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'b')\n",
    "# plt.xlabel('TASTES_AND_PREFERENCES')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# mobile_logins #\n",
    "# plt.subplot(2, 2, 3)\n",
    "# sns.distplot(apprentice_chef['MOBILE_LOGINS'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'g')\n",
    "# plt.xlabel('MOBILE_LOGINS')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# pc_logins #\n",
    "# plt.subplot(2, 2, 4)\n",
    "# sns.distplot(apprentice_chef['PC_LOGINS'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'b')\n",
    "# plt.xlabel('PC_LOGINS')\n",
    "# plt.ylabel('frequency')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "# Figure and axis size #\n",
    "# fig, ax = plt.subplots(figsize = (10, 10)) # fitting the axis \n",
    "\n",
    "# weekly_plan #\n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.distplot(apprentice_chef['WEEKLY_PLAN'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'r')\n",
    "# plt.xlabel('WEEKLY_PLAN')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# early_deliveries #\n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.distplot(apprentice_chef['EARLY_DELIVERIES'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'y')\n",
    "# plt.xlabel('EARLY_DELIVERIES')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# late_deliveries # \n",
    "# plt.subplot(2, 2, 3)\n",
    "# sns.distplot(apprentice_chef['LATE_DELIVERIES'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'r')\n",
    "# plt.xlabel('LATE_DELIVERIES')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# package_locker #  \n",
    "# plt.subplot(2, 2, 4)\n",
    "# sns.distplot(apprentice_chef['PACKAGE_LOCKER'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'y')\n",
    "# plt.xlabel('PACKAGE_LOCKER')\n",
    "# plt.ylabel('frequency')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "# Figure and axis size #\n",
    "# fig, ax = plt.subplots(figsize = (10, 10)) # fitting the axis \n",
    "\n",
    "# refrigerated_locker #  \n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.distplot(apprentice_chef['REFRIGERATED_LOCKER'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'g')\n",
    "# plt.xlabel('REFRIGATED_LOCKER')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# followed_recommendations_pct # \n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.distplot(apprentice_chef['FOLLOWED_RECOMMENDATIONS_PCT'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'b')\n",
    "# plt.xlabel('FOLLOWED_RECOMMENDATIONS_PCT')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# avg_prep_vid_time # \n",
    "# plt.subplot(2, 2, 3)\n",
    "# sns.distplot(apprentice_chef['AVG_PREP_VID_TIME'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'g')\n",
    "# plt.xlabel('AVG_PREP_VID_TIME')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# largest_order_size #\n",
    "# plt.subplot(2, 2, 4)\n",
    "# sns.distplot(apprentice_chef['LARGEST_ORDER_SIZE'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'b')\n",
    "# plt.xlabel('LARGEST_ORDER_SIZE')\n",
    "# plt.ylabel('frequency')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "# Figure and axis size #\n",
    "# fig, ax = plt.subplots(figsize = (10, 10)) # fitting the axis \n",
    "\n",
    "# master_classes_attended # \n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.distplot(apprentice_chef['MASTER_CLASSES_ATTENDED'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'r')\n",
    "# plt.xlabel('MASTER_CLASSES_ATTENDED')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# median_meal_rating #\n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.distplot(apprentice_chef['MEDIAN_MEAL_RATING'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'y')\n",
    "# plt.xlabel('MEDIAN_MEAL_RATING')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# avg_clicks_per_visit #\n",
    "# plt.subplot(2, 2, 3)\n",
    "# sns.distplot(apprentice_chef['AVG_CLICKS_PER_VISIT'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'r')\n",
    "# plt.xlabel('AVG_CLICKS_PER_VISIT')\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# total_photos_viewed #            \n",
    "# plt.subplot(2, 2, 4)\n",
    "# sns.distplot(apprentice_chef['TOTAL_PHOTOS_VIEWED'],\n",
    "#              bins  = 'fd',\n",
    "#              color = 'y')\n",
    "# plt.xlabel('TOTAL_PHOTOS_VIEWED')\n",
    "# plt.ylabel('frequency')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the target variable is binary (1 = Yes, 0 = No), the scatterplot would be logistical with two output; 1 por 0. It is important to visualize the graph as we could create a threshold on the changes. Same goes for the scatterplot, I will be commenting out to make my notebook run efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Scatterplot for trend change detection #####\n",
    "\n",
    "# Figure and axis size #\n",
    "# fig, ax = plt.subplots(figsize = (10, 10)) # fitting the axis \n",
    "\n",
    "# total_meals_ordered #\n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.scatterplot(x = apprentice_chef['TOTAL_MEALS_ORDERED'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'r')\n",
    "# plt.xlabel('total_meals_ordered')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # unique_meals_purch #\n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.scatterplot(x = apprentice_chef['UNIQUE_MEALS_PURCH'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'r')\n",
    "# plt.xlabel('unique_meals_purch')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "\n",
    "# # contacts_w_customer_service #\n",
    "# plt.subplot(2, 2, 3)\n",
    "# sns.scatterplot(x = apprentice_chef['CONTACTS_W_CUSTOMER_SERVICE'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'r')\n",
    "# plt.xlabel('contacts_w_customer_service')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "\n",
    "# # product_categories_viewed #\n",
    "# plt.subplot(2, 2, 4)\n",
    "# sns.scatterplot(x = apprentice_chef['PRODUCT_CATEGORIES_VIEWED'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'r')\n",
    "# plt.xlabel('product_categories_viewed')\n",
    "# plt.ylabel('cross sell success')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('AC Scatter 1')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# ##############################################################################\n",
    "\n",
    "# # Figure and axis size #\n",
    "# fig, ax = plt.subplots(figsize = (10, 10)) # fitting the axis \n",
    "\n",
    "# # avg_time_per_site_visit # \n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.scatterplot(x = apprentice_chef['AVG_TIME_PER_SITE_VISIT'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'b')\n",
    "# plt.xlabel('avg_time_per_site_visit')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # mobile_number # \n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.scatterplot(x = apprentice_chef['MOBILE_NUMBER'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'b')\n",
    "# plt.xlabel('mobile_number')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # cancellations_before_noon # \n",
    "# plt.subplot(2, 2, 3)\n",
    "# sns.scatterplot(x = apprentice_chef['CANCELLATIONS_BEFORE_NOON'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'b')\n",
    "# plt.xlabel('cancellations_before_noon')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # cancellations_after_noon #\n",
    "# plt.subplot(2, 2, 4)\n",
    "# sns.scatterplot(x = apprentice_chef['CANCELLATIONS_AFTER_NOON'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'b')\n",
    "# plt.xlabel('cancellations_after_noon')\n",
    "# plt.ylabel('cross sell success')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('AC Scatter 2')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# ##############################################################################\n",
    "\n",
    "# # Figure and axis size #\n",
    "# fig, ax = plt.subplots(figsize = (10, 10)) # fitting the axis \n",
    "\n",
    "# # tastes_and_preferences #\n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.scatterplot(x = apprentice_chef['TASTES_AND_PREFERENCES'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'g')\n",
    "# plt.xlabel('tastes_and_preferences')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # mobile_logins #\n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.scatterplot(x = apprentice_chef['MOBILE_LOGINS'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'g')\n",
    "# plt.xlabel('mobile_logins')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # pc_logins #\n",
    "# plt.subplot(2, 2, 3)\n",
    "# sns.scatterplot(x = apprentice_chef['PC_LOGINS'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'g')\n",
    "# plt.xlabel('pc_logins')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # weekly_plan #\n",
    "# plt.subplot(2, 2, 4)\n",
    "# sns.scatterplot(x = apprentice_chef['WEEKLY_PLAN'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'g')\n",
    "# plt.xlabel('weekly_plan')\n",
    "# plt.ylabel('cross sell success')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('AC Scatter 3')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# ##############################################################################\n",
    "\n",
    "# # Figure and axis size #\n",
    "# fig, ax = plt.subplots(figsize = (10, 10)) # fitting the axis \n",
    "\n",
    "# # early_deliveries #\n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.scatterplot(x = apprentice_chef['EARLY_DELIVERIES'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'y')\n",
    "# plt.xlabel('early_deliveries')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # late_deliveries # \n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.scatterplot(x = apprentice_chef['LATE_DELIVERIES'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'y')\n",
    "# plt.xlabel('late_deliveries')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # package_locker #  \n",
    "# plt.subplot(2, 2, 3)\n",
    "# sns.scatterplot(x = apprentice_chef['PACKAGE_LOCKER'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'y')\n",
    "# plt.xlabel('package_locker')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # refrigerated_locker #  \n",
    "# plt.subplot(2, 2, 4)\n",
    "# sns.scatterplot(x = apprentice_chef['REFRIGERATED_LOCKER'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'y')\n",
    "# plt.xlabel('refrigerated_locker')\n",
    "# plt.ylabel('cross sell success')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('AC Scatter 4')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# ##############################################################################\n",
    "\n",
    "# # Figure and axis size #\n",
    "# fig, ax = plt.subplots(figsize = (10, 10)) # fitting the axis \n",
    "\n",
    "# # followed_recommendations_pct # \n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.scatterplot(x = apprentice_chef['FOLLOWED_RECOMMENDATIONS_PCT'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'r')\n",
    "# plt.xlabel('followed_recommendations_pct')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # avg_prep_vid_time # \n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.scatterplot(x = apprentice_chef['AVG_PREP_VID_TIME'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'r')\n",
    "# plt.xlabel('avg_prep_vid_time')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # largest_order_size #\n",
    "# plt.subplot(2, 2, 3)\n",
    "# sns.scatterplot(x = apprentice_chef['LARGEST_ORDER_SIZE'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'r')\n",
    "# plt.xlabel('largest_order_size')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # master_classes_attended # \n",
    "# plt.subplot(2, 2, 4)\n",
    "# sns.scatterplot(x = apprentice_chef['MASTER_CLASSES_ATTENDED'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'r')\n",
    "# plt.xlabel('master_classes_attended')\n",
    "# plt.ylabel('cross sell success')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('AC Scatter 5')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# ##############################################################################\n",
    "\n",
    "# # Figure and axis size #\n",
    "# fig, ax = plt.subplots(figsize = (10, 10)) # fitting the axis \n",
    "\n",
    "# # median_meal_rating #\n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.scatterplot(x = apprentice_chef['MEDIAN_MEAL_RATING'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'b')\n",
    "# plt.xlabel('median_meal_rating')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # avg_clicks_per_visit #\n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.scatterplot(x = apprentice_chef['AVG_CLICKS_PER_VISIT'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'b')\n",
    "# plt.xlabel('avg_clicks_per_visit')\n",
    "# plt.ylabel('cross sell success')\n",
    "\n",
    "# # total_photos_viewed #            \n",
    "# plt.subplot(2, 2, 3)\n",
    "# sns.scatterplot(x = apprentice_chef['TOTAL_PHOTOS_VIEWED'],\n",
    "#                y = apprentice_chef['CROSS_SELL_SUCCESS'],\n",
    "#                color = 'b')\n",
    "# plt.xlabel('total_photos_viewed')\n",
    "# plt.ylabel('cross sell success')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('AC Scatter 6')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exploratory stage, we can see that there are patterns from the barplot and the scatterplot. For example, the avg_time_per_site_visit scatterplot indicates that there is an outlier on the person who subscribe to the cross sell promotion. A customer who spends on average of 1600 seconds on the website has subscribe to the cross sell promotion service but the scatterplot shows that on average customers who spent around 0 - 600 seconds has a subscribes to the cross sell promotion services. This is interesting because when we visualise the data, we can identify different patterns and trends that can be useful for the analysis and feature engineering stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, I will be analyzing the variables on the dataset and conduct feature engineering process. I will check the presence of an outlier and create an outlier threshold to create a new variable. Also, I will creating new features based on the variables that are presented in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.1 Creating a new features based on the variables on the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will be creating new features. The method that I will be doing is to combine two or more variables that can create a new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.1.1 Average number of meal ordered that follows the meal recommendation that was generated for them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this feature, I would like to create a feature on the average number of meals that followed the recommendation that was provided. For example, a customer orders 200 meals in total and 50% of the time they follow the recommendations. This new feature showcases the number of meals that follows the recommendations and the one that doesn't follow the recommendation. In this case, we can assume that out of the 200 meals, 100 of them the customer cooked the meal with the recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the FOLLOWED_RECOMMENDATIONS_PCT column into a percentage format #\n",
    "\n",
    "apprentice_chef['FOLLOWED_RECOMMENDATIONS_PCT'] = apprentice_chef['FOLLOWED_RECOMMENDATIONS_PCT'] / 100\n",
    "\n",
    "# Number of meal prepared that follows the recommendation #\n",
    "\n",
    "apprentice_chef['TOTAL_MEAL_FOLLOWED_RECOMMENDATIONS'] = apprentice_chef['TOTAL_MEALS_ORDERED'] * apprentice_chef['FOLLOWED_RECOMMENDATIONS_PCT']\n",
    "\n",
    "# Round the value into 2 decimal point #\n",
    "\n",
    "apprentice_chef['TOTAL_MEAL_FOLLOWED_RECOMMENDATIONS'] = apprentice_chef['TOTAL_MEAL_FOLLOWED_RECOMMENDATIONS'].round(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.1.2 Average number of meal ordered that does not follows the meal recommendation that was generated for them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vice versa, I have created a new feature with the number of meal prepared that doesn't follow the recommendations. I simply subtract the total meals ordered with the number of meal prepared that follows the recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of meal prepared that does not follows the recommendation #\n",
    "\n",
    "apprentice_chef['TOTAL_MEAL_NOT_FOLLOWED_RECOMMENDATIONS'] = apprentice_chef['TOTAL_MEALS_ORDERED'] - apprentice_chef['TOTAL_MEAL_FOLLOWED_RECOMMENDATIONS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.1.3 Average meal price per month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this feature, I would like to calculate the average price meal per month for each customer. Based on the case study, the lowest price for one meal is 10 dollars and the highest price for one meal is 23 dollars. This is the pricing excluding the beverages. I cannot identify if the customer ordered drinks or not so in this case, I would assume that this is the price for meals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average price for one meal per month #\n",
    "\n",
    "apprentice_chef['AVERAGE_MEAL_PRICE_PER_MONTH'] = apprentice_chef['REVENUE'] / apprentice_chef['TOTAL_MEALS_ORDERED']\n",
    "\n",
    "# Rounding of to 2 decimal points #\n",
    "\n",
    "apprentice_chef['AVERAGE_MEAL_PRICE_PER_MONTH'] = apprentice_chef['AVERAGE_MEAL_PRICE_PER_MONTH'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.1.4 Average meal ordered per month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this feature, I would like to know the average number of meal ordered per month for each customer. To do this, I would simply get the total meals ordered column and divided each of the rows with 12 as the dataset is collected in the span of 12 months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average total meal ordered per month #\n",
    "\n",
    "apprentice_chef['AVERAGE_MEAL_ORDERED_PER_MONTH'] = apprentice_chef['TOTAL_MEALS_ORDERED'] / 12\n",
    "\n",
    "# Rounding off to 2 decimal points #\n",
    "\n",
    "apprentice_chef['AVERAGE_MEAL_ORDERED_PER_MONTH'] = apprentice_chef['AVERAGE_MEAL_ORDERED_PER_MONTH'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.1.5 Total number of cancellation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this feature, I would like to combine the number of cancellation before and after noon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of cancellation #\n",
    "\n",
    "apprentice_chef['TOTAL_CANCELLATION'] = apprentice_chef['CANCELLATIONS_BEFORE_NOON'] + apprentice_chef['CANCELLATIONS_AFTER_NOON']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.1.6 Total Number of Login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this feature, I would like to create the total number of login by combining the number of login via PC and login via mobile for each customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of login #\n",
    "\n",
    "apprentice_chef['TOTAL_LOGIN'] = apprentice_chef['MOBILE_LOGINS'] + apprentice_chef['PC_LOGINS']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.1.7 Total number of normal delivery per customer & Average number of normal deliveries per customer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this feature, I would like to know the number of normal deliveries and special deliveries. The definition of normal deliveries is the the number of deliveries that are within the designated delivery windows. Special deliveries is the number of early deliveries + late deliveries. \n",
    "\n",
    "I will be adding both early and late deliveries and the result will be used as a divisor to total meal ordered. There is a limitation in this feature as we are assuming that person orders one meal.\n",
    "\n",
    "I will be able to create two features:\n",
    "1. Total number of special deliveries per customer\n",
    "2. Total number of normal deliveries per customer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the number of early deliveries and late deliveries to create total number of special deliveries #\n",
    "apprentice_chef['TOTAL_SPECIAL_DELIVERIES'] = apprentice_chef['EARLY_DELIVERIES'] + apprentice_chef['LATE_DELIVERIES']\n",
    "\n",
    "# Creating the total number of normal deliveries #\n",
    "apprentice_chef['TOTAL_NORMAL_DELIVERIES'] = apprentice_chef['TOTAL_MEALS_ORDERED'] - apprentice_chef['TOTAL_SPECIAL_DELIVERIES']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.1.8 Average customer engagement per site visit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this feature, I would calculate it by dividing the product categories viewed with the average click per visit. I want to create a feature that showcase the value of the website. The variables that are connected to the website are \"AVG_TIME_PER_SITE_VISIT\", \"PRODUCT_CATEGORIES_VIEWED\", \"AVG_CLICKS_PER_VISIT\" and \"TOTAL_PHOTOS_VIEWED\".In this case, I would like to measure the engagement in the website by looking on their average click per visit and the product categories that they are viewing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating average customer engagement per site visit #\n",
    "\n",
    "apprentice_chef['AVG_CUSTOMER_ENGAGEMENT'] = apprentice_chef['PRODUCT_CATEGORIES_VIEWED'] / apprentice_chef['AVG_CLICKS_PER_VISIT']\n",
    "\n",
    "# Rounding it to 2 decimal places #\n",
    "apprentice_chef['AVG_CUSTOMER_ENGAGEMENT'] = apprentice_chef['AVG_CUSTOMER_ENGAGEMENT'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.2 Handling the categorical variable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create more features, I would like to analyze the categorical variables. These variables are \"NAME\", \"EMAIL\", \"FIRST_NAME\" and \"LAST_NAME\". The method that I will be using to transform my categorical variables is the dummy variables method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.2.1 Separating the email name and the email domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am trying to separate the email name and the domain name in the \"EMAIL\" column. The purpose of this separation is to group the customers to different domains (\"personal\", \"junk\", \"professional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting email names: name and domain ###\n",
    "\n",
    "# Placeholder list #\n",
    "placeholder_lst = []\n",
    "\n",
    "# Creating a for loop to separate the domain and email name #\n",
    "for index, col in apprentice_chef.iterrows():\n",
    "    split_email = apprentice_chef.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    placeholder_lst.append(split_email)\n",
    "\n",
    "# Creating a new dataframe for the separate email name and domain #\n",
    "email_df = pd.DataFrame(placeholder_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I created a separate data frame with two variables: email name and email domain, I will be concatenating the email domain into the apprentice_chef data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmail.com           303\n",
       "protonmail.com      284\n",
       "yahoo.com           274\n",
       "msn.com              72\n",
       "aol.com              69\n",
       "passport.com         64\n",
       "hotmail.com          63\n",
       "live.com             62\n",
       "me.com               59\n",
       "amex.com             30\n",
       "jnj.com              28\n",
       "mcdonalds.com        28\n",
       "cocacola.com         28\n",
       "merck.com            28\n",
       "nike.com             27\n",
       "apple.com            27\n",
       "ibm.com              26\n",
       "ge.org               26\n",
       "dupont.com           26\n",
       "chevron.com          25\n",
       "microsoft.com        25\n",
       "unitedhealth.com     24\n",
       "travelers.com        24\n",
       "exxon.com            24\n",
       "boeing.com           23\n",
       "verizon.com          22\n",
       "mmm.com              22\n",
       "pg.com               22\n",
       "caterpillar.com      22\n",
       "disney.com           21\n",
       "walmart.com          21\n",
       "pfizer.com           20\n",
       "visa.com             20\n",
       "jpmorgan.com         19\n",
       "unitedtech.com       18\n",
       "goldmansacs.com      18\n",
       "cisco.com            18\n",
       "intel.com            17\n",
       "homedepot.com        17\n",
       "Name: email_domain, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Concatenating the new email domain with the  original dataset ###\n",
    "\n",
    "# Renaming the column #\n",
    "email_df.columns = ['email_name', 'email_domain']\n",
    "\n",
    "# Concatenating email_domain with apprentice_chef df #\n",
    "apprentice_chef = pd.concat([apprentice_chef, email_df.loc[ : , 'email_domain']],\n",
    "                           axis=1)\n",
    "\n",
    "# Checking the counts on each domain #\n",
    "apprentice_chef.loc[ : , 'email_domain'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.2.2 Creating a new column for the dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I am creating two list that contains the name of the personal domains and junk domains. With this, I will create a for loop to categorize the email. After that, I will create a new variable name called DOMAIN_GROUP and add it to the apprentice_chef data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Categorising the email type by domain ###\n",
    "\n",
    "# Creating a list of domain types #\n",
    "\n",
    "personal_email_domains = ['@gmail.com', '@yahoo.com', '@protonmail.com']\n",
    "junk_email_domains = ['@me.com','@aol.com', '@hotmail.com', '@live.com', '@msn.com',\n",
    "                    '@passport.com']\n",
    "\n",
    "# placeholder list #\n",
    "placeholder_lst = []\n",
    "\n",
    "# Creating a loop for categorising email domain #\n",
    "for domain in apprentice_chef['email_domain']:\n",
    "    if '@' + domain in personal_email_domains:\n",
    "        placeholder_lst.append('personal')\n",
    "    elif '@' + domain in junk_email_domains:\n",
    "        placeholder_lst.append('junk')\n",
    "    else:\n",
    "        placeholder_lst.append('professional')\n",
    "        \n",
    "# Concatenating with original DataFrame #\n",
    "apprentice_chef['DOMAIN_GROUP'] = pd.Series(placeholder_lst)\n",
    "\n",
    "# Checking the count of each email type #\n",
    "# apprentice_chef['DOMAIN_GROUP'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will be creating a dummy variable for each of the domain names in the DOMAIN GROUP column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a dummy variable for the email domain ###\n",
    "\n",
    "#one hot encoding categorical variables #\n",
    "one_hot_domain_group = pd.get_dummies(apprentice_chef['DOMAIN_GROUP'])\n",
    "\n",
    "# Joining codings together #\n",
    "apprentice_chef = apprentice_chef.join([one_hot_domain_group])\n",
    "\n",
    "# saving new columns #\n",
    "new_columns = apprentice_chef.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.2.3 Dummy variables for median meal rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to create a dummy variables for the median meal rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding categorical variables #\n",
    "one_hot_median_meal_rating = pd.get_dummies(apprentice_chef['MEDIAN_MEAL_RATING'])\n",
    "\n",
    "# Joining codings together #\n",
    "apprentice_chef = apprentice_chef.join([one_hot_median_meal_rating])\n",
    "\n",
    "# saving new columns #\n",
    "new_columns = apprentice_chef.columns\n",
    "\n",
    "# Renaming the column names #\n",
    "apprentice_chef.rename(columns={1:'VERY_LOW_MEAL_RATING',\n",
    "                                2:'LOW_MEAL_RATING',\n",
    "                                3:'NEUTRAL_MEAL_RATING',\n",
    "                                4:'HIGH_MEAL_RATING',\n",
    "                                5:'VERY_HIGH_MEAL_RATING'},\n",
    "                                inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.3 Outlier Threshold "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my last feature engineering process, I will be creating outliers threshold. The purpose of creating this outliers threshold is to capture the noise of each of the variable. With more feature is created with the threshold, hopefully it will increase the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the outliers threshold #\n",
    "\n",
    "REVENUE_hi                      = 3000\n",
    "TOTAL_MEALS_ORDERED_hi          = 150\n",
    "UNIQUE_MEALS_PURCH_hi           = 7\n",
    "CONTACTS_W_CUSTOMER_SERVICE_lo  = 4\n",
    "CONTACTS_W_CUSTOMER_SERVICE_hi  = 9\n",
    "AVG_TIME_PER_SITE_VISIT_hi      = 180\n",
    "CANCELLATIONS_BEFORE_NOON_hi    = 1\n",
    "CANCELLATIONS_AFTER_NOON_hi     = 2\n",
    "MOBILE_LOGINS_lo                = 5\n",
    "MOBILE_LOGINS_hi                = 6\n",
    "PC_LOGINS_lo                    = 1\n",
    "PC_LOGINS_hi                    = 2\n",
    "WEEKLY_PLAN_hi                  = 15\n",
    "EARLY_DELIVERIES_hi             = 2\n",
    "LATE_DELIVERIES_hi              = 5\n",
    "AVG_PREP_VID_TIME_hi            = 200\n",
    "LARGEST_ORDER_SIZE_lo           = 2\n",
    "LARGEST_ORDER_SIZE_hi           = 6\n",
    "MASTER_CLASSES_ATTENDED_hi      = 2\n",
    "AVG_CLICKS_PER_VISIT_lo         = 10\n",
    "TOTAL_PHOTOS_VIEWED_hi          = 500\n",
    "TOTAL_PHOTOS_VIEWED_lo          = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I created the threshold for the outliers, I will be creating new columns for each of the outliers that I have identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating the outlier columns  ###\n",
    "\n",
    "# REVENUE #\n",
    "\n",
    "apprentice_chef['OUT_REVENUE'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_REVENUE'][apprentice_chef['REVENUE'] \n",
    "                                                                 > REVENUE_hi]\n",
    "\n",
    "apprentice_chef['OUT_REVENUE'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# TOTAL_MEALS_ORDERED #\n",
    "\n",
    "apprentice_chef['OUT_TOTAL_MEALS_ORDERED'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_TOTAL_MEALS_ORDERED'][apprentice_chef['TOTAL_MEALS_ORDERED'] \n",
    "                                                                 > TOTAL_MEALS_ORDERED_hi]\n",
    "\n",
    "apprentice_chef['OUT_TOTAL_MEALS_ORDERED'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# UNIQUE_MEALS_PURCH #\n",
    "\n",
    "apprentice_chef['OUT_UNIQUE_MEALS_PURCH'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_UNIQUE_MEALS_PURCH'][apprentice_chef['UNIQUE_MEALS_PURCH'] \n",
    "                                                                 > UNIQUE_MEALS_PURCH_hi ]\n",
    "\n",
    "apprentice_chef['OUT_UNIQUE_MEALS_PURCH'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# CONTACTS_W_CUSTOMER_SERVICE #\n",
    "\n",
    "apprentice_chef['OUT_CONTACTS_W_CUSTOMER_SERVICE'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_CONTACTS_W_CUSTOMER_SERVICE'][apprentice_chef['CONTACTS_W_CUSTOMER_SERVICE']\n",
    "                                                                         > CONTACTS_W_CUSTOMER_SERVICE_hi]\n",
    "condition_lo = apprentice_chef.loc[0:,'OUT_CONTACTS_W_CUSTOMER_SERVICE'][apprentice_chef['CONTACTS_W_CUSTOMER_SERVICE'] \n",
    "                                                                         < CONTACTS_W_CUSTOMER_SERVICE_lo]                                                                 \n",
    "\n",
    "apprentice_chef['OUT_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "apprentice_chef['OUT_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# AVG_TIME_PER_SITE_VISIT #\n",
    "\n",
    "apprentice_chef['OUT_AVG_TIME_PER_SITE_VISIT'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_AVG_TIME_PER_SITE_VISIT'][apprentice_chef['AVG_TIME_PER_SITE_VISIT']\n",
    "                                                                         > AVG_TIME_PER_SITE_VISIT_hi]\n",
    "\n",
    "apprentice_chef['OUT_AVG_TIME_PER_SITE_VISIT'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# CANCELLATIONS_BEFORE_NOON #\n",
    "\n",
    "apprentice_chef['OUT_CANCELLATIONS_BEFORE_NOON'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_CANCELLATIONS_BEFORE_NOON'][apprentice_chef['CANCELLATIONS_BEFORE_NOON']\n",
    "                                                                         > CANCELLATIONS_BEFORE_NOON_hi]\n",
    "\n",
    "apprentice_chef['OUT_CANCELLATIONS_BEFORE_NOON'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# CANCELLATIONS_AFTER_NOON #\n",
    "\n",
    "apprentice_chef['OUT_CANCELLATIONS_AFTER_NOON'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_CANCELLATIONS_AFTER_NOON'][apprentice_chef['CANCELLATIONS_AFTER_NOON']\n",
    "                                                                         > CANCELLATIONS_AFTER_NOON_hi]\n",
    "\n",
    "apprentice_chef['OUT_CANCELLATIONS_AFTER_NOON'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "\n",
    "# EARLY_DELIVERIES # \n",
    "\n",
    "apprentice_chef['OUT_EARLY_DELIVERIES'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_EARLY_DELIVERIES'][apprentice_chef['EARLY_DELIVERIES'] \n",
    "                                                                 > EARLY_DELIVERIES_hi]\n",
    "\n",
    "apprentice_chef['OUT_EARLY_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "# LATE_DELIVERIES # \n",
    "\n",
    "apprentice_chef['OUT_LATE_DELIVERIES'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_LATE_DELIVERIES'][apprentice_chef['LATE_DELIVERIES'] \n",
    "                                                                 > LATE_DELIVERIES_hi]\n",
    "\n",
    "apprentice_chef['OUT_LATE_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# AVG_PREP_VID_TIME #\n",
    "\n",
    "apprentice_chef['OUT_AVG_PREP_VID_TIME'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_AVG_PREP_VID_TIME'][apprentice_chef['AVG_PREP_VID_TIME'] \n",
    "                                                                 > AVG_PREP_VID_TIME_hi]\n",
    "\n",
    "apprentice_chef['OUT_AVG_PREP_VID_TIME'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# LARGEST_ORDER_SIZE #\n",
    "\n",
    "apprentice_chef['OUT_LARGEST_ORDER_SIZE'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_LARGEST_ORDER_SIZE'][apprentice_chef['LARGEST_ORDER_SIZE']\n",
    "                                                                         > LARGEST_ORDER_SIZE_hi]\n",
    "condition_lo = apprentice_chef.loc[0:,'OUT_LARGEST_ORDER_SIZE'][apprentice_chef['LARGEST_ORDER_SIZE'] \n",
    "                                                                         < LARGEST_ORDER_SIZE_lo]                                                                 \n",
    "\n",
    "apprentice_chef['OUT_LARGEST_ORDER_SIZE'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "apprentice_chef['OUT_LARGEST_ORDER_SIZE'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# MASTER_CLASSES_ATTENDED #\n",
    "\n",
    "apprentice_chef['OUT_MASTER_CLASSES_ATTENDED'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_MASTER_CLASSES_ATTENDED'][apprentice_chef['MASTER_CLASSES_ATTENDED'] \n",
    "                                                                 > MASTER_CLASSES_ATTENDED_hi]\n",
    "\n",
    "apprentice_chef['OUT_MASTER_CLASSES_ATTENDED'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "\n",
    "# AVG_CLICKS_PER_VISIT # \n",
    "\n",
    "apprentice_chef['OUT_AVG_CLICKS_PER_VISIT'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_lo = apprentice_chef.loc[0:,'OUT_AVG_CLICKS_PER_VISIT'][apprentice_chef['AVG_CLICKS_PER_VISIT'] \n",
    "                                                                         < AVG_CLICKS_PER_VISIT_lo]                                                                 \n",
    "\n",
    "apprentice_chef['OUT_AVG_CLICKS_PER_VISIT'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# TOTAL_PHOTOS_VIEWED #\n",
    "\n",
    "apprentice_chef['OUT_TOTAL_PHOTOS_VIEWED'] = 0\n",
    "\n",
    "# Creating the condition for outliers #\n",
    "condition_hi = apprentice_chef.loc[0:,'OUT_TOTAL_PHOTOS_VIEWED'][apprentice_chef['TOTAL_PHOTOS_VIEWED']\n",
    "                                                                         > TOTAL_PHOTOS_VIEWED_hi]\n",
    "condition_lo = apprentice_chef.loc[0:,'OUT_TOTAL_PHOTOS_VIEWED'][apprentice_chef['TOTAL_PHOTOS_VIEWED'] \n",
    "                                                                         < TOTAL_PHOTOS_VIEWED_lo]                                                                 \n",
    "\n",
    "apprentice_chef['OUT_TOTAL_PHOTOS_VIEWED'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "apprentice_chef['OUT_TOTAL_PHOTOS_VIEWED'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 3.4 Dropping categorical variables  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step for the feature engineering is to drop all of the unnecessary variables; variables that has no added value to the model. This is mostly for the categorical variables but for analysis purpose, I will keep \"NAME\" in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary variables #\n",
    "\n",
    "apprentice_chef = apprentice_chef.drop('EMAIL', axis = 1)\n",
    "apprentice_chef = apprentice_chef.drop('FIRST_NAME', axis = 1)\n",
    "apprentice_chef = apprentice_chef.drop('FAMILY_NAME', axis = 1)\n",
    "apprentice_chef = apprentice_chef.drop('email_domain', axis = 1)\n",
    "apprentice_chef = apprentice_chef.drop('DOMAIN_GROUP', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping all of the unnecessary variables, I will save this dataset to Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the dataset into Excel #\n",
    "\n",
    "# apprentice_chef.to_excel('A2_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 4. Building Classification Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, I will be creating different classification model using the featured engineered dataset. I will be creating these models:\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Decision Tree\n",
    "3. k-Nearest Neighbors\n",
    "4. Naive Bayes Classifier\n",
    "5. Random Forest\n",
    "\n",
    "But first, I will check the correlation for each of the variables with the target variable \"CROSS_SELL_SUCCESS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation for target variable and each explanatory variable #\n",
    "\n",
    "#df_corr = apprentice_chef.corr().round(2)\n",
    "\n",
    "#df_corr['CROSS_SELL_SUCCESS'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 4.1 Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will be creating the logistical regression in sci-kit learn. Before that, I would like to give credit to Professor Chase Kusterer from Hult International Business School that has created the def functio <strong>optimal_neighbors</strong> and <strong> visual_cm </strong> which I will be using in my analysis.\n",
    "\n",
    "For the <strong>optimal_neighbors</strong> def function, it is basically the function to find the optimized number of n is KNN Classifier model. Most of the functions is default and it will also plot the visualization of the 'optimized' number of neighbors.\n",
    "\n",
    "For the <strong> visual_cm </strong>, it is a def function to plot the confusion matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optimal neighbors ###\n",
    "\n",
    "def optimal_neighbors(X_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=222,\n",
    "                      response_type='class',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing X_data #\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(X_data)\n",
    "        X_scaled           = scaler.transform(X_data)\n",
    "        X_scaled_df        = pd.DataFrame(X_scaled)\n",
    "        X_data             = X_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train_test_split #\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy #\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range #\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type #\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy #\n",
    "        training_accuracy.append(clf.score(X_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy #\n",
    "        test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization #\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors #\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object #\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # plotting the heatmap #\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Reds',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create a dictionary on two list: \n",
    "1. Candidate model with the full variables\n",
    "2. Candidate model with the significant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dictionary for the candidate models #\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    "# all variables from the full model #\n",
    " 'logit_full'   : ['REVENUE', 'TOTAL_MEALS_ORDERED', 'UNIQUE_MEALS_PURCH','CONTACTS_W_CUSTOMER_SERVICE',\n",
    "                   'PRODUCT_CATEGORIES_VIEWED','AVG_TIME_PER_SITE_VISIT', 'MOBILE_NUMBER', \n",
    "                   'CANCELLATIONS_BEFORE_NOON', 'CANCELLATIONS_AFTER_NOON', 'TASTES_AND_PREFERENCES',\n",
    "                   'MOBILE_LOGINS','PC_LOGINS','WEEKLY_PLAN','EARLY_DELIVERIES','LATE_DELIVERIES',\n",
    "                   'PACKAGE_LOCKER','REFRIGERATED_LOCKER','FOLLOWED_RECOMMENDATIONS_PCT','AVG_PREP_VID_TIME',\n",
    "                   'LARGEST_ORDER_SIZE','MASTER_CLASSES_ATTENDED','MEDIAN_MEAL_RATING','AVG_CLICKS_PER_VISIT',\n",
    "                   'TOTAL_PHOTOS_VIEWED','TOTAL_MEAL_FOLLOWED_RECOMMENDATIONS', \n",
    "                   'TOTAL_MEAL_NOT_FOLLOWED_RECOMMENDATIONS','AVERAGE_MEAL_PRICE_PER_MONTH',\n",
    "                   'AVERAGE_MEAL_ORDERED_PER_MONTH','TOTAL_CANCELLATION','TOTAL_LOGIN','TOTAL_SPECIAL_DELIVERIES',\n",
    "                   'TOTAL_NORMAL_DELIVERIES','AVG_CUSTOMER_ENGAGEMENT', 'junk','personal','professional',\n",
    "                   'VERY_LOW_MEAL_RATING','LOW_MEAL_RATING','NEUTRAL_MEAL_RATING','HIGH_MEAL_RATING',\n",
    "                   'VERY_HIGH_MEAL_RATING', 'OUT_REVENUE', 'OUT_TOTAL_MEALS_ORDERED','OUT_UNIQUE_MEALS_PURCH',\n",
    "                   'OUT_CONTACTS_W_CUSTOMER_SERVICE','OUT_AVG_TIME_PER_SITE_VISIT','OUT_CANCELLATIONS_BEFORE_NOON',\n",
    "                   'OUT_CANCELLATIONS_AFTER_NOON','OUT_EARLY_DELIVERIES', 'OUT_LATE_DELIVERIES', \n",
    "                   'OUT_AVG_PREP_VID_TIME','OUT_LARGEST_ORDER_SIZE','OUT_MASTER_CLASSES_ATTENDED',\n",
    "                   'OUT_AVG_CLICKS_PER_VISIT','OUT_TOTAL_PHOTOS_VIEWED'],\n",
    " \n",
    "# significant variables from the full model #\n",
    " 'logit_sig'    : ['FOLLOWED_RECOMMENDATIONS_PCT' , 'TOTAL_MEAL_FOLLOWED_RECOMMENDATIONS', \n",
    "                   'professional', 'junk', 'OUT_CANCELLATIONS_BEFORE_NOON','CANCELLATIONS_BEFORE_NOON',\n",
    "                   'OUT_TOTAL_MEALS_ORDERED']\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the dictionary, I will now build my logistic regression in Scikit-learn using the logit_sig variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7464\n",
      "Testing  ACCURACY: 0.7351\n"
     ]
    }
   ],
   "source": [
    "# train/test split with the significant full model #\n",
    "apprentice_chef_data   =  apprentice_chef.loc[ : , candidate_dict['logit_sig']]\n",
    "apprentice_chef_target =  apprentice_chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# Creating the default SEED #\n",
    "SEED = 222\n",
    "\n",
    "# Train_test_split the data #\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            apprentice_chef_data,\n",
    "            apprentice_chef_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = SEED,\n",
    "            stratify     = apprentice_chef_target)\n",
    "\n",
    "\n",
    "# Instantiating the logistic regression model #\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = SEED)\n",
    "\n",
    "\n",
    "# Fitting the training data #\n",
    "logreg_fit = logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting based on the testing set #\n",
    "logreg_pred = logreg_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# Print the scoring results #\n",
    "print('Training ACCURACY:', logreg_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(X_test, y_test).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this logistic regression, the metric that is used to measure how good the model is accuracy. However, accuracy has some downside. We only measure accuracy from one end. If we predict that only 67% of the customers subscribe to the cross sell promotion, we can only be 67% accurate during the analysis stage which is bad. In this case, confusion matrix is the tool that is more appropriate for measuring classification model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an illustration of the confusion matrix based on the analysis context:\n",
    "\n",
    "~~~  \n",
    "  True Positives                                        False Positives \n",
    "  PREDICTED: Subscriber (CROSS_SELL_SUCCESS = 1)     |  PREDICTED: Non-subscriber (CROSS_SELL_SUCCESS = 0)\n",
    "  ACTUAL:    Subscriber (CROSS_SELL_SUCCESS = 1)     |  ACTUAL:    Subscriber     (CROSS_SELL_SUCCESS = 1)\n",
    "                                                     |\n",
    "  ---------------------------------------------------|----------------------------------------------------\n",
    "                                                     |  \n",
    "  False Negatives                                    |  True Negatives\n",
    "  PREDICTED: Subscriber     (CROSS_SELL_SUCCESS = 1) |  PREDICTED: Non-subscriber (CROSS_SELL_SUCCESS = 0)\n",
    "  ACTUAL:    Non-subscriber (CROSS_SELL_SUCCESS = 0) |  ACTUAL:    Non-subscriber (CROSS_SELL_SUCCESS = 0)\n",
    "  \n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating the confusion matrix #\n",
    "\n",
    "# print(confusion_matrix(y_true = y_test,\n",
    "#                        y_pred = logreg_pred))\n",
    "\n",
    "# # Visualizing the confusion matrix using the visual_cm def function #\n",
    "# visual_cm(true_y = y_test,\n",
    "#           pred_y = logreg_pred,\n",
    "#           labels = ['Subscriber', 'Non-subscriber'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other most common metrics that is used to measure classification models is the area under the curve (AUC). The AUC takes into account on both sensitivity and specificity. Sensitivity is the measurement of the proportion of correctly identified values that are positive. Specificity is the measurement of the proportion of correctly identified values that are negatives. In our final model, I would like to showcase the model's training accuracy, testing accuracy and AUC value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculating the AUC curve #\n",
    "# roc_auc_score(y_true  = y_test,\n",
    "#               y_score = logreg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be creating a code that would let me save each model's performance for my final results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Model', 'Training Accuracy', 'Testing Accuracy', 'AUC Value']\n",
      "['Logistic Regression', 0.7464, 0.7351, 0.6916]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list #\n",
    "model_performance = [['Model', 'Training Accuracy',\n",
    "                      'Testing Accuracy', 'AUC Value']]\n",
    "\n",
    "\n",
    "# train accuracy #\n",
    "logreg_train_acc  = logreg_fit.score(X_train, y_train).round(4)\n",
    "\n",
    "\n",
    "# test accuracy #\n",
    "logreg_test_acc   = logreg_fit.score(X_test, y_test).round(4)\n",
    "\n",
    "\n",
    "# auc value #\n",
    "logreg_auc = roc_auc_score(y_true  = y_test,\n",
    "                           y_score = logreg_pred).round(4)\n",
    "\n",
    "\n",
    "# saving the results #\n",
    "model_performance.append(['Logistic Regression',\n",
    "                          logreg_train_acc,\n",
    "                          logreg_test_acc,\n",
    "                          logreg_auc])\n",
    "\n",
    "\n",
    "# printing the results #\n",
    "for model in model_performance:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 4.2 KNN Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second mode that I would do is the k-Nearest Neighbors(KNN). For the KNN classification model, I would like to scale my explanatory variables and I would also like to identify the optimal number of the neighbors using the <strong> optimal_neighbors </strong>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is: 18\n"
     ]
    }
   ],
   "source": [
    "# Plotting the optimal number for neighbors #\n",
    "\n",
    "opt_neighbors = optimal_neighbors(X_data = X_train,\n",
    "                                 y_data = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.6765\n",
      "Testing  ACCURACY: 0.6797\n",
      "AUC Score        : 0.6916\n"
     ]
    }
   ],
   "source": [
    "### Scaling the explanatory variable and building the KNN classification model ###\n",
    "\n",
    "# Instantiating the  StandardScaler() #\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the data #\n",
    "scaler.fit(apprentice_chef_data)\n",
    "\n",
    "# Transforming the data #\n",
    "X_scaled = scaler.transform(apprentice_chef_data)\n",
    "\n",
    "# converting the X_scaled into a DataFrame #\n",
    "X_scaled_df = pd.DataFrame(X_scaled) \n",
    "\n",
    "# train_test_split of the scaled data #\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            X_scaled_df,\n",
    "            apprentice_chef_target,\n",
    "            random_state = SEED,\n",
    "            test_size = 0.25,\n",
    "            stratify = apprentice_chef_target)\n",
    "\n",
    "# instantiating a KNN classification model with optimal neighbors #\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "# fitting the training data #\n",
    "knn_fit = knn_opt.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# predicting based on the testing set #\n",
    "knn_pred = knn_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# printing the results #\n",
    "print('Training ACCURACY:', knn_opt.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', knn_opt.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = logreg_pred).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I got the result for the KNN classification model, I will be saving the result on the model performance that I created before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Model', 'Training Accuracy', 'Testing Accuracy', 'AUC Value']\n",
      "['Logistic Regression', 0.7464, 0.7351, 0.6916]\n",
      "['KNN Classification', 0.8019, 0.7864, 0.5017]\n"
     ]
    }
   ],
   "source": [
    "# train accuracy for KNN #\n",
    "knn_train_acc = knn_fit.score(X_train_scaled, y_train_scaled).round(4)\n",
    "\n",
    "\n",
    "# test accuracy for KNN #\n",
    "knn_test_acc  = knn_fit.score(X_test_scaled, y_test_scaled).round(4)\n",
    "\n",
    "\n",
    "# auc value for KNN #\n",
    "knn_auc       = roc_auc_score(y_true  = y_test_scaled,\n",
    "                              y_score = knn_pred).round(4)\n",
    "\n",
    "\n",
    "# saving the results #\n",
    "model_performance.append(['KNN Classification',\n",
    "                          knn_train_acc,\n",
    "                          knn_test_acc,\n",
    "                          knn_auc])\n",
    "\n",
    "\n",
    "# printing the results #\n",
    "for model in model_performance:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 4.3 Classification Trees (CART Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be creating the CART model or simply known as the decision trees or classification trees. The advantage of a CART model is that it is easy to interpret so it is really useful model for analysis and insights. However, it is also known for its bad prediction metric so it is a bad model for predictive analysis. For this model, I would like to give credit Professor Chase Kusterer from Hult International Business School for creating the def function <strong> plot_feature_importances </strong> that I will be using for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_feature_importances #\n",
    "\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "\n",
    "# declaring the number\n",
    "    n_features = X_train.shape[1]\n",
    "    \n",
    "# setting plot window #\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the CART model, I will be making two models: Full Tree and Pruned Tree. The Full Tree is the model with default settings while the Pruned Tree's setting will be tuned. I will be creating the Full Tree model first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8986\n",
      "Testing  ACCURACY: 0.7741\n",
      "AUC Score        : 0.761\n"
     ]
    }
   ],
   "source": [
    "# instantiating a classification tree object #\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# fitting the training data #\n",
    "full_tree_fit = full_tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predicting on new data #\n",
    "full_tree_pred = full_tree_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# printing the model #\n",
    "print('Training ACCURACY:', full_tree_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', full_tree_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_tree_pred).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will add the result from the Full Tree model into our model performance list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Model', 'Training Accuracy', 'Testing Accuracy', 'AUC Value']\n",
      "['Logistic Regression', 0.7464, 0.7351, 0.6916]\n",
      "['KNN Classification', 0.8019, 0.7864, 0.5017]\n",
      "['Full Tree', 0.8986, 0.7741, 0.761]\n"
     ]
    }
   ],
   "source": [
    "# train accuracy #\n",
    "full_tree_train_acc = full_tree_fit.score(X_train, y_train).round(4)\n",
    "\n",
    "\n",
    "# test accuracy #\n",
    "full_tree_test_acc  = full_tree_fit.score(X_test, y_test).round(4)\n",
    "\n",
    "\n",
    "# auc value #\n",
    "full_tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                                    y_score = full_tree_pred).round(4)\n",
    "\n",
    "\n",
    "# saving the results #\n",
    "model_performance.append(['Full Tree',\n",
    "                          full_tree_train_acc,\n",
    "                          full_tree_test_acc,\n",
    "                          full_tree_auc])\n",
    "\n",
    "\n",
    "# printing the results #\n",
    "for model in model_performance:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will be creating the Pruned Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7923\n",
      "Testing  ACCURACY: 0.809\n",
      "AUC Score        : 0.7883\n"
     ]
    }
   ],
   "source": [
    "# instantiating a classification tree object #\n",
    "tree_pruned      = DecisionTreeClassifier(max_depth = 4,\n",
    "                                          min_samples_leaf = 25,\n",
    "                                          random_state = SEED)\n",
    "\n",
    "\n",
    "# fitting the training data #\n",
    "tree_pruned_fit  = tree_pruned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predicting on new data #\n",
    "tree_pruned_pred = tree_pruned_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# Printing the model #\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_pruned_pred).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will add the Pruned Tree model into our list. To make it more appealing, I would put the results into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy #\n",
    "p_tree_train_acc = tree_pruned_fit.score(X_train, y_train).round(4)\n",
    "\n",
    "\n",
    "# test accuracy #\n",
    "p_tree_test_acc  = tree_pruned_fit.score(X_test, y_test).round(4)\n",
    "\n",
    "\n",
    "# auc value #\n",
    "p_tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = tree_pruned_pred).round(4)\n",
    "\n",
    "\n",
    "# saving the results #\n",
    "model_performance.append(['Pruned Tree',\n",
    "                          p_tree_train_acc,\n",
    "                          p_tree_test_acc,\n",
    "                          p_tree_auc])\n",
    "\n",
    "\n",
    "# converting to DataFrame and checking the results #\n",
    "model_performance = pd.DataFrame(model_performance[1:], columns = model_performance[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantage of CART model is that it can help me evaluate each of the variable's performance towards the model. It would help me on picking on the important features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting feature importance\n",
    "# plot_feature_importances(tree_pruned_fit,\n",
    "#                          train = X_train,\n",
    "#                          export = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, TOTAL_MEAL_NOT_FOLLOWED_RECOMMENDATIONS and TOTAL_CANCELLATION is not important at all so if I want to change my significant candidate model, I could drop this variable and evaluate the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 4.4 Hyperparameter Tuning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my 4th model, I will be using the hyperparameter tuning method to tuned the Logistic Regression model and the CART model. The purpose of hyperparameter tuning is to boost the score for the training accuracy, testing accuracy and auc value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 4.4.1 Tuned Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do hyperparameter tuning, I need to create the grid of the hyperparameter first and then run the train_test_split function. I will be using the GridSearchCV to find the optimal score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### GridSearchCV ###\n",
    "\n",
    "# # declaring a hyperparameter space\n",
    "# C_space          = pd.np.arange(10.0, 20.0, 5.0)\n",
    "# warm_start_space = [True, False]\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'C'          : C_space,\n",
    "#               'warm_start' : warm_start_space}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# lr_tuned = LogisticRegression(solver = 'lbfgs',\n",
    "#                               max_iter = 1000,\n",
    "#                               random_state = SEED)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# lr_tuned_cv = GridSearchCV(estimator  = lr_tuned,\n",
    "#                            param_grid = param_grid,\n",
    "#                            cv         = 5,\n",
    "#                            scoring    = make_scorer(roc_auc_score,\n",
    "#                                                     needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# lr_tuned_cv.fit(apprentice_chef_data, apprentice_chef_target)\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "# print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to find the best parameter for the logistic regression. To do this, I would simply run the best_estimator_ code and it will show me the requirements for the logistic regression function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7464\n",
      "Testing  ACCURACY: 0.7331\n",
      "AUC Score        : 0.6867\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the logistic regression model #\n",
    "lr_tuned = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 10,\n",
    "                            warm_start = True,\n",
    "                            random_state = SEED)\n",
    "\n",
    "\n",
    "# Fitting the training data #\n",
    "lr_tuned_fit = lr_tuned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting based on the testing set #\n",
    "lr_tuned_pred = lr_tuned_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# Print the scoring results #\n",
    "print('Training ACCURACY:', lr_tuned.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', lr_tuned.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                  y_score = lr_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be saving the tuned Logistic Regression result on the model performance dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>AUC Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classification</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.7610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy  Testing Accuracy  AUC Value\n",
       "0  Logistic Regression             0.7464            0.7351     0.6916\n",
       "1   KNN Classification             0.8019            0.7864     0.5017\n",
       "2            Full Tree             0.8986            0.7741     0.7610\n",
       "3          Pruned Tree             0.7923            0.8090     0.7883\n",
       "4             Tuned LR             0.7464            0.7331     0.6867"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects #\n",
    "lr_train_acc = lr_tuned.score(X_train, y_train).round(4)\n",
    "lr_test_acc  = lr_tuned.score(X_test, y_test).round(4)\n",
    "lr_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = lr_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending tuned LR to model_performance #\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model'             : 'Tuned LR',\n",
    "                          'Training Accuracy'  : lr_train_acc,\n",
    "                          'Testing Accuracy'   : lr_test_acc,\n",
    "                          'AUC Value'          : lr_auc},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# printing the results #\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 4.4.2 Tuned Classification Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the tuned logistic regression, I would now do hyperparameter tuning for my classification trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# criterion_space = ['gini', 'entropy']\n",
    "# splitter_space = ['best', 'random']\n",
    "# depth_space = pd.np.arange(1, 25)\n",
    "# leaf_space  = pd.np.arange(1, 100)\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'criterion'        : criterion_space,\n",
    "#               'splitter'         : splitter_space,\n",
    "#               'max_depth'        : depth_space,\n",
    "#               'min_samples_leaf' : leaf_space}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# tuned_tree = DecisionTreeClassifier(random_state = SEED)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# tuned_tree_cv = GridSearchCV(estimator  = tuned_tree,\n",
    "#                              param_grid = param_grid,\n",
    "#                              cv         = 3,\n",
    "#                              scoring    = make_scorer(roc_auc_score,\n",
    "#                                                       needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# tuned_tree_cv.fit(apprentice_chef_data, apprentice_chef_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now fit the best estimator parameter to my tuned tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7923\n",
      "Testing  ACCURACY: 0.809\n",
      "AUC Score        : 0.784\n"
     ]
    }
   ],
   "source": [
    "# Instantiating a classification tree object #\n",
    "tuned_tree    = DecisionTreeClassifier(max_depth = 1,\n",
    "                                          criterion = 'gini',\n",
    "                                          min_samples_leaf = 1,\n",
    "                                          splitter = 'best')\n",
    "\n",
    "\n",
    "# fitting the training data #\n",
    "tuned_tree_fit  = tuned_tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predicting on new data #\n",
    "tuned_tree_pred = tuned_tree_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# printing the model #\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tuned_tree_pred).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will add the result to the model performance dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>AUC Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classification</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.7610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.7064</td>\n",
       "      <td>0.7840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy  Testing Accuracy  AUC Value\n",
       "0  Logistic Regression             0.7464            0.7351     0.6916\n",
       "1   KNN Classification             0.8019            0.7864     0.5017\n",
       "2            Full Tree             0.8986            0.7741     0.7610\n",
       "3          Pruned Tree             0.7923            0.8090     0.7883\n",
       "4             Tuned LR             0.7464            0.7331     0.6867\n",
       "5           Tuned Tree             0.7300            0.7064     0.7840"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects #\n",
    "tree_train_acc = tuned_tree.score(X_train, y_train).round(4)\n",
    "tree_test_acc  = tuned_tree.score(X_test, y_test).round(4)\n",
    "tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = tuned_tree_pred).round(4)\n",
    "\n",
    "\n",
    "# appending tuned tree to model_performance #\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model'             : 'Tuned Tree',\n",
    "                          'Training Accuracy'  : tree_train_acc,\n",
    "                          'Testing Accuracy'   : tree_test_acc,\n",
    "                          'AUC Value'          : tree_auc},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# printing the results #\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 4.5 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest model is an ensemble learning method where it creates different decision tree and takes the mode of the entire result which will results in a more accurate prediction. For this model, I will be using my logit_sig variables which has all of my significant variables and my logit_full which is the all of the variables in my dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do the logit_sig model first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split with the logit_sig variables #\n",
    "apprentice_chef_data   =  apprentice_chef.loc[ : , candidate_dict['logit_sig']]\n",
    "apprentice_chef_target =  apprentice_chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    " \n",
    "# train_test_split #\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            apprentice_chef_data,\n",
    "            apprentice_chef_target,\n",
    "            random_state = SEED,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = apprentice_chef_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will instantiate the default random forest model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.891\n",
      "Testing  ACCURACY: 0.7762\n",
      "AUC Score        : 0.7608\n"
     ]
    }
   ],
   "source": [
    "# Instantiating a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 10,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = None,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = SEED)\n",
    "\n",
    "# Fitting the training data #\n",
    "rf_default_fit = rf_default.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predicting based on the testing set #\n",
    "rf_default_fit_pred = rf_default_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# printing the results #\n",
    "print('Training ACCURACY:', rf_default_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be saving my random forest into the model performance dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>AUC Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classification</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.7610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.7064</td>\n",
       "      <td>0.7840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.7608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy  Testing Accuracy  AUC Value\n",
       "0  Logistic Regression             0.7464            0.7351     0.6916\n",
       "1   KNN Classification             0.8019            0.7864     0.5017\n",
       "2            Full Tree             0.8986            0.7741     0.7610\n",
       "3          Pruned Tree             0.7923            0.8090     0.7883\n",
       "4             Tuned LR             0.7464            0.7331     0.6867\n",
       "5           Tuned Tree             0.7300            0.7064     0.7840\n",
       "6        Random Forest             0.8910            0.7762     0.7608"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects #\n",
    "rf_train_acc = rf_default_fit.score(X_train, y_train).round(4)\n",
    "rf_test_acc  = rf_default_fit.score(X_test, y_test).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = rf_default_fit_pred).round(4)\n",
    "\n",
    "\n",
    "# appending random forest to model_performance #\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model'             : 'Random Forest',\n",
    "                          'Training Accuracy'  : rf_train_acc,\n",
    "                          'Testing Accuracy'   : rf_test_acc,\n",
    "                          'AUC Value'          : rf_auc},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# printing the results #\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will use the logit_full for the data to fit to the random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split with the logit_full variables #\n",
    "apprentice_chef_data   =  apprentice_chef.loc[ : , candidate_dict['logit_full']]\n",
    "apprentice_chef_target =  apprentice_chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "# train_test_split #\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
    "            apprentice_chef_data,\n",
    "            apprentice_chef_target,\n",
    "            random_state = SEED,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = apprentice_chef_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.9849\n",
      "Testing  ACCURACY: 0.7639\n",
      "AUC Score        : 0.7568\n"
     ]
    }
   ],
   "source": [
    "# Instantiating a random forest model with default values #\n",
    "rf_default_full = RandomForestClassifier(n_estimators     = 10,\n",
    "                                         criterion        = 'gini',\n",
    "                                         max_depth        = None,\n",
    "                                         min_samples_leaf = 1,\n",
    "                                         bootstrap        = True,\n",
    "                                         warm_start       = False,\n",
    "                                         random_state     = SEED)\n",
    "\n",
    "\n",
    "# Fitting the training data #\n",
    "rf_default_full_fit = rf_default_full.fit(X_train_full, y_train_full)\n",
    "\n",
    "\n",
    "# Predicting based on the testing set #\n",
    "rf_default_full_pred = rf_default_full_fit.predict(X_test_full)\n",
    "\n",
    "\n",
    "# Printing the results #\n",
    "print('Training ACCURACY:', rf_default_full_fit.score(X_train_full, y_train_full).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_full_fit.score(X_test_full, y_test_full).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_full,\n",
    "                                          y_score = rf_default_full_pred).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will do a hyperparameter tuning on the random forest model. The first step that I would do is doing the default function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# estimator_space  = pd.np.arange(100, 1100, 250)\n",
    "# leaf_space       = pd.np.arange(1, 31, 10)\n",
    "# criterion_space  = ['gini', 'entropy']\n",
    "# bootstrap_space  = [True, False]\n",
    "# warm_start_space = [True, False]\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'n_estimators'     : estimator_space,\n",
    "#               'min_samples_leaf' : leaf_space,\n",
    "#               'criterion'        : criterion_space,\n",
    "#               'bootstrap'        : bootstrap_space,\n",
    "#               'warm_start'       : warm_start_space}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# full_forest_grid = RandomForestClassifier(random_state = SEED)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# full_forest_cv = GridSearchCV(estimator  = full_forest_grid,\n",
    "#                               param_grid = param_grid,\n",
    "#                               cv         = 3,\n",
    "#                               scoring    = make_scorer(roc_auc_score,\n",
    "#                                            needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# full_forest_cv.fit(apprentice_chef_data, apprentice_chef_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", full_forest_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", full_forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this model,I will be tuning the hyperparameters with the most optimized tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8074\n",
      "Testing  ACCURACY: 0.8029\n",
      "AUC Score        : 0.7686\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the model object with hyperparameters #\n",
    "full_rf_tuned = RandomForestClassifier(bootstrap        = True,\n",
    "                                       criterion        = 'gini',\n",
    "                                       min_samples_leaf = 11,\n",
    "                                       n_estimators     = 850,\n",
    "                                       warm_start       = True,\n",
    "                                       random_state     = SEED)\n",
    "\n",
    "\n",
    "# Fitting the dataset #\n",
    "full_rf_tuned_fit = full_rf_tuned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting based on the testing set #\n",
    "full_rf_tuned_pred = full_rf_tuned_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# Printing the results #\n",
    "print('Training ACCURACY:', full_rf_tuned_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', full_rf_tuned_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_rf_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I build my random forest and tuned random forest model, I will be saving it on my model performance dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>AUC Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classification</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.7610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.7064</td>\n",
       "      <td>0.7840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.7608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Random Forest</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.7686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy  Testing Accuracy  AUC Value\n",
       "0  Logistic Regression             0.7464            0.7351     0.6916\n",
       "1   KNN Classification             0.8019            0.7864     0.5017\n",
       "2            Full Tree             0.8986            0.7741     0.7610\n",
       "3          Pruned Tree             0.7923            0.8090     0.7883\n",
       "4             Tuned LR             0.7464            0.7331     0.6867\n",
       "5           Tuned Tree             0.7300            0.7064     0.7840\n",
       "6        Random Forest             0.8910            0.7762     0.7608\n",
       "7  Tuned Random Forest             0.8074            0.8029     0.7686"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects #\n",
    "rf_train_acc = full_rf_tuned_fit.score(X_train, y_train).round(4)\n",
    "rf_test_acc  = full_rf_tuned_fit.score(X_test, y_test).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = full_rf_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending the tuned random forest to model_performance #\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model'             : 'Tuned Random Forest',\n",
    "                          'Training Accuracy'  : rf_train_acc,\n",
    "                          'Testing Accuracy'   : rf_test_acc,\n",
    "                          'AUC Value'          : rf_auc},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# Printing the results #\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 4.6 Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last model that I will create is the gradient boosting classifier. This model is similar to the random forest but rather than looking at the entire model, it will learn from its previous model. I visualize it as the kaizen method where continuous improvement where you look at your previous mistake/problem and keep improving the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be creating the gradient boosting classifier with the default settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8245\n",
      "Testing ACCURACY : 0.809\n",
      "AUC Score        : 0.7968\n"
     ]
    }
   ],
   "source": [
    "# Instatiating the model object with hyperparameters #\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 3,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = SEED)\n",
    "\n",
    "\n",
    "# Fitting the dataset #\n",
    "full_gbm_default_fit = full_gbm_default.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting based on the testing set #\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# Printing the results #\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(X_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>AUC Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classification</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.7610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.7064</td>\n",
       "      <td>0.7840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.7608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Random Forest</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.7686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GBM</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.7968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy  Testing Accuracy  AUC Value\n",
       "0  Logistic Regression             0.7464            0.7351     0.6916\n",
       "1   KNN Classification             0.8019            0.7864     0.5017\n",
       "2            Full Tree             0.8986            0.7741     0.7610\n",
       "3          Pruned Tree             0.7923            0.8090     0.7883\n",
       "4             Tuned LR             0.7464            0.7331     0.6867\n",
       "5           Tuned Tree             0.7300            0.7064     0.7840\n",
       "6        Random Forest             0.8910            0.7762     0.7608\n",
       "7  Tuned Random Forest             0.8074            0.8029     0.7686\n",
       "8                  GBM             0.8245            0.8090     0.7968"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects #\n",
    "gbm_train_acc = full_gbm_default_fit.score(X_train, y_train).round(4)\n",
    "gbm_test_acc  = full_gbm_default_fit.score(X_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = full_gbm_default_pred).round(4)\n",
    "\n",
    "\n",
    "# appending the GBM to model_performance #\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model'             : 'GBM',\n",
    "                          'Training Accuracy'  : gbm_train_acc,\n",
    "                          'Testing Accuracy'   : gbm_test_acc,\n",
    "                          'AUC Value'          : gbm_auc},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# Printing the results #\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will conduct a grid search cv to find the optimized parameters for gradient boosting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# learn_space     = pd.np.arange(0.1, 1.6, 0.3)\n",
    "# estimator_space = pd.np.arange(50, 250, 50)\n",
    "# depth_space     = pd.np.arange(1, 10)\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'learning_rate' : learn_space,\n",
    "#               'max_depth'     : depth_space,\n",
    "#               'n_estimators'  : estimator_space}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# full_gbm_grid = GradientBoostingClassifier(random_state = 802)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# full_gbm_cv = GridSearchCV(estimator  = full_gbm_grid,\n",
    "#                            param_grid = param_grid,\n",
    "#                            cv         = 3,\n",
    "#                            scoring    = make_scorer(roc_auc_score,\n",
    "#                                         needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# full_gbm_cv.fit(apprentice_chef_data, apprentice_chef_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will be using the parameters from the best estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8053\n",
      "Testing  ACCURACY: 0.8029\n",
      "AUC Score        : 0.7923\n"
     ]
    }
   ],
   "source": [
    "# Tuned GBM 3rd Version #\n",
    "\n",
    "# Setting the SEED #\n",
    "SEED = 222\n",
    "\n",
    "# Instantiating the GradientBoostingClassifier #\n",
    "gbm_tuned = GradientBoostingClassifier(loss = 'deviance',\n",
    "                                       criterion ='friedman_mse',\n",
    "                                       learning_rate = 0.5,\n",
    "                                       max_depth     = 1,\n",
    "                                       min_samples_leaf = 2,\n",
    "                                       min_samples_split = 2,\n",
    "                                       n_estimators  = 125,\n",
    "                                       random_state  = SEED)\n",
    "\n",
    "\n",
    "# Fitting the dataset #\n",
    "gbm_tuned_fit = gbm_tuned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting based on the testing set #\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# Printing the results #\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>AUC Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classification</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.7610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.7064</td>\n",
       "      <td>0.7840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.7608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Random Forest</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.7686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GBM</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.7968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned GBM</td>\n",
       "      <td>0.8053</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.7923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy  Testing Accuracy  AUC Value\n",
       "0  Logistic Regression             0.7464            0.7351     0.6916\n",
       "1   KNN Classification             0.8019            0.7864     0.5017\n",
       "2            Full Tree             0.8986            0.7741     0.7610\n",
       "3          Pruned Tree             0.7923            0.8090     0.7883\n",
       "4             Tuned LR             0.7464            0.7331     0.6867\n",
       "5           Tuned Tree             0.7300            0.7064     0.7840\n",
       "6        Random Forest             0.8910            0.7762     0.7608\n",
       "7  Tuned Random Forest             0.8074            0.8029     0.7686\n",
       "8                  GBM             0.8245            0.8090     0.7968\n",
       "9            Tuned GBM             0.8053            0.8029     0.7923"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects #\n",
    "gbm_train_acc = gbm_tuned_fit.score(X_train, y_train).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(X_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending the Tuned GBM to model_performance #\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model'             : 'Tuned GBM',\n",
    "                          'Training Accuracy'  : gbm_train_acc,\n",
    "                          'Testing Accuracy'   : gbm_test_acc,\n",
    "                          'AUC Value'          : gbm_auc},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results #\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7958\n",
      "Testing  ACCURACY: 0.8172\n",
      "AUC Score        : 0.8029\n"
     ]
    }
   ],
   "source": [
    "# Tuned GBM 4th Version #\n",
    "\n",
    "# Setting the SEED #\n",
    "SEED = 222\n",
    "\n",
    "# Instantiating the GradientBoostingClassifier #\n",
    "gbm_tuned = GradientBoostingClassifier(loss = 'exponential',\n",
    "                                       criterion ='friedman_mse',\n",
    "                                       learning_rate = 0.1,\n",
    "                                       max_depth     = 1,\n",
    "                                       n_estimators  = 100,\n",
    "                                       random_state  = SEED)\n",
    "\n",
    "\n",
    "# Fitting the dataset #\n",
    "gbm_tuned_fit = gbm_tuned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting based on the testing set #\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# Printing the results #\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>AUC Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classification</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.7610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.7064</td>\n",
       "      <td>0.7840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.7608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Random Forest</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.7686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GBM</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.7968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned GBM</td>\n",
       "      <td>0.8053</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.7923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tuned GBM 2nd Version</td>\n",
       "      <td>0.7958</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.8029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Training Accuracy  Testing Accuracy  AUC Value\n",
       "0     Logistic Regression             0.7464            0.7351     0.6916\n",
       "1      KNN Classification             0.8019            0.7864     0.5017\n",
       "2               Full Tree             0.8986            0.7741     0.7610\n",
       "3             Pruned Tree             0.7923            0.8090     0.7883\n",
       "4                Tuned LR             0.7464            0.7331     0.6867\n",
       "5              Tuned Tree             0.7300            0.7064     0.7840\n",
       "6           Random Forest             0.8910            0.7762     0.7608\n",
       "7     Tuned Random Forest             0.8074            0.8029     0.7686\n",
       "8                     GBM             0.8245            0.8090     0.7968\n",
       "9               Tuned GBM             0.8053            0.8029     0.7923\n",
       "10  Tuned GBM 2nd Version             0.7958            0.8172     0.8029"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects #\n",
    "gbm_train_acc = gbm_tuned_fit.score(X_train, y_train).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(X_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending the tuned gbm 2nd to model_performance #\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model'             : 'Tuned GBM 2nd Version',\n",
    "                          'Training Accuracy'  : gbm_train_acc,\n",
    "                          'Testing Accuracy'   : gbm_test_acc,\n",
    "                          'AUC Value'          : gbm_auc},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results #\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> 5. Conclusion of the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the models that I have build, the <strong>\tTuned GBM 2nd Version </strong> has the best AUC Value: 0.8029. Other model such as <strong> Pruned Tree </strong> has also a good result but the CART models are known for their bad prediction accuracy. \n",
    "\n",
    "There are few things that I can do to improve my model:\n",
    "1. Add more feature that is significant to the target variables.\n",
    "2. Hyperparameter tuning each model in more details.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
